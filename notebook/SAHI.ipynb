{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a12513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T04:50:17.917132Z",
     "start_time": "2022-02-03T04:50:17.904558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b418a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T04:50:19.063284Z",
     "start_time": "2022-02-03T04:50:18.117444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Showing help with the command 'sahi -- --help'.\n",
      "\n",
      "\u001b[1mNAME\u001b[0m\n",
      "    sahi\n",
      "\n",
      "\u001b[1mSYNOPSIS\u001b[0m\n",
      "    sahi \u001b[4mGROUP\u001b[0m | \u001b[4mCOMMAND\u001b[0m | \u001b[4mVALUE\u001b[0m\n",
      "\n",
      "\u001b[1mGROUPS\u001b[0m\n",
      "    \u001b[1m\u001b[4mGROUP\u001b[0m\u001b[0m is one of the following:\n",
      "\n",
      "     coco\n",
      "\n",
      "\u001b[1mCOMMANDS\u001b[0m\n",
      "    \u001b[1m\u001b[4mCOMMAND\u001b[0m\u001b[0m is one of the following:\n",
      "\n",
      "     predict\n",
      "       Performs prediction for all present images in given folder.\n",
      "\n",
      "     predict-fiftyone\n",
      "       Performs prediction for all present images in given folder.\n",
      "\n",
      "\u001b[1mVALUES\u001b[0m\n",
      "    \u001b[1m\u001b[4mVALUE\u001b[0m\u001b[0m is one of the following:\n",
      "\n",
      "     version\n"
     ]
    }
   ],
   "source": [
    "!sahi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7292e54b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T04:50:19.993126Z",
     "start_time": "2022-02-03T04:50:19.064983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Showing help with the command 'sahi coco slice -- --help'.\n",
      "\n",
      "\u001b[1mNAME\u001b[0m\n",
      "    sahi coco slice\n",
      "\n",
      "\u001b[1mSYNOPSIS\u001b[0m\n",
      "    sahi coco slice \u001b[4mIMAGE_DIR\u001b[0m \u001b[4mDATASET_JSON_PATH\u001b[0m <flags>\n",
      "\n",
      "\u001b[1mPOSITIONAL ARGUMENTS\u001b[0m\n",
      "    \u001b[1m\u001b[4mIMAGE_DIR\u001b[0m\u001b[0m\n",
      "        Type: str\n",
      "        directory for coco images\n",
      "    \u001b[1m\u001b[4mDATASET_JSON_PATH\u001b[0m\u001b[0m\n",
      "        Type: str\n",
      "        file path for the coco dataset json file slice_size (int)\n",
      "\n",
      "\u001b[1mFLAGS\u001b[0m\n",
      "    --slice_size=\u001b[4mSLICE_SIZE\u001b[0m\n",
      "        Type: int\n",
      "        Default: 512\n",
      "    --overlap_ratio=\u001b[4mOVERLAP_RATIO\u001b[0m\n",
      "        Type: float\n",
      "        Default: 0.2\n",
      "        slice overlap ratio\n",
      "    --ignore_negative_samples=\u001b[4mIGNORE_NEGATIVE_SAMPLES\u001b[0m\n",
      "        Type: bool\n",
      "        Default: False\n",
      "        ignore images without annotation\n",
      "    --project=\u001b[4mPROJECT\u001b[0m\n",
      "        Type: str\n",
      "        Default: 'runs/slice_coco'\n",
      "        save results to project/name\n",
      "    --name=\u001b[4mNAME\u001b[0m\n",
      "        Type: str\n",
      "        Default: 'exp'\n",
      "        save results to project/name\n",
      "    --min_area_ratio=\u001b[4mMIN_AREA_RATIO\u001b[0m\n",
      "        Type: float\n",
      "        Default: 0.1\n",
      "        If the cropped annotation area to original annotation ratio is smaller than this value, the annotation is filtered out. Default 0.1.\n",
      "\n",
      "\u001b[1mNOTES\u001b[0m\n",
      "    You can also use flags syntax for POSITIONAL ARGUMENTS\n"
     ]
    }
   ],
   "source": [
    "!sahi coco slice -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714faf70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T04:50:21.263965Z",
     "start_time": "2022-02-03T04:50:19.994594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4328, 9), (4707, 9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append(\"../src\")\n",
    "import util\n",
    "import subprocess\n",
    "\n",
    "df = pd.read_csv(\"../../data/tensorflow-great-barrier-reef/train.csv\")\n",
    "\n",
    "df['annotations'] = df['annotations'].apply(lambda x: ast.literal_eval(x))\n",
    "df['num_bbox'] = df['annotations'].apply(len)        \n",
    "\n",
    "folds = util.load_pickle(\"../input/fold_test_2.pkl\")\n",
    "df[\"fold\"] = df[\"sequence\"].apply(lambda x: folds[x])\n",
    "\n",
    "highFP_df = pd.read_csv('../input/df_highFPNoBB.csv')\n",
    "df = pd.merge(df, highFP_df[['video_id',\"video_frame\",\"highFBNoBB\"]], on=[\"video_id\",\"video_frame\"], how='left')\n",
    "df[\"highFBNoBB\"].fillna(False)\n",
    "\n",
    "\n",
    "df_train = df.query(\"fold == 0 and (num_bbox > 0 or highFBNoBB)\").copy()\n",
    "df_valid = df.query(\"fold == 1\").copy()\n",
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38549c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T04:50:21.795680Z",
     "start_time": "2022-02-03T04:50:21.264864Z"
    }
   },
   "outputs": [],
   "source": [
    "json_train_f = util.coco(df_train)\n",
    "json_valid_f = util.coco(df_valid)\n",
    "\n",
    "with open('../../data/tensorflow-great-barrier-reef/annotations_train_v2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_train_f, f, ensure_ascii=True, indent=4)\n",
    "    \n",
    "with open('../../data/tensorflow-great-barrier-reef/annotations_valid_v2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_valid_f, f, ensure_ascii=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d705699b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T19:51:40.903767Z",
     "start_time": "2022-02-03T19:51:40.541226Z"
    }
   },
   "outputs": [],
   "source": [
    "df_whole = df.query(\"num_bbox > 0 or highFBNoBB\")\n",
    "json_f = util.coco(df_whole)\n",
    "with open('../../data/tensorflow-great-barrier-reef/annotations_wholeRun_v2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_f, f, ensure_ascii=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d44db4",
   "metadata": {},
   "source": [
    "# Create Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9ebc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T15:36:46.413665Z",
     "start_time": "2022-02-03T15:36:46.394249Z"
    }
   },
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "?slice_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb3db2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:01:14.927949Z",
     "start_time": "2022-02-03T20:01:14.908233Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/images/\"\n",
    "#SLICE_HEIGHT = 400 # 720 // 1.8 \n",
    "#SLICE_WIDTH = 711 # 1280 // 1.8\n",
    "\n",
    "SLICE_HEIGHT = 720 \n",
    "SLICE_WIDTH = 720 \n",
    "\n",
    "overlap_ratio = 0.2\n",
    "# 4 sample per picture\n",
    "ignore_negative_samples = False\n",
    "project = \"/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/sliced/\"\n",
    "min_area_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66699aae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T16:02:53.040252Z",
     "start_time": "2022-02-03T16:00:03.251920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 4328/4328 [00:00<00:00, 7515.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4328/4328 [01:25<00:00, 50.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████████████████████████████████████████████████████████████████████████████████| 4707/4707 [00:00<00:00, 51601.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4707/4707 [01:20<00:00, 58.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_path in ['/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/annotations_train_v2.json',\n",
    "                 '/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/annotations_valid_v2.json']:\n",
    "    name = f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/train/\" if \"train\" in data_path else f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/test\"\n",
    "    json_file = \"instances_train\" if \"train\" in data_path else \"instances_test\" \n",
    "    res = slice_coco(\n",
    "        coco_annotation_file_path = data_path,\n",
    "        image_dir = IMAGE_DIR,\n",
    "        output_dir = project + \"/\" + name,\n",
    "        output_coco_annotation_file_name = json_file,\n",
    "        slice_height = SLICE_HEIGHT,\n",
    "        slice_width = SLICE_WIDTH,\n",
    "        min_area_ratio = min_area_ratio,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf6b3e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T16:06:35.378657Z",
     "start_time": "2022-02-03T16:06:35.358554Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "for data_path in ['/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/annotations_train_v2.json',\n",
    "                 '/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/annotations_valid_v2.json']:\n",
    "    is_train = \"train\" in data_path\n",
    "    post_name = \"train\" if is_train else \"test\"\n",
    "    file_pre = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    name =  f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/train/\" if \"train\" in data_path else f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/test\"\n",
    "    source_annot = project + \"/\" + name + \"/\" + \"instances_\" + post_name\n",
    "    to_annot_folder = project + \"/\" + f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}\" + \"/\" + \"annotations\" + \"/\"\n",
    "    to_annot = to_annot_folder + \"/\" \n",
    "    if not os.path.exists(to_annot_folder):\n",
    "        os.makedirs(to_annot_folder)\n",
    "    shutil.move(source_annot, to_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "772fd242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T16:07:16.414956Z",
     "start_time": "2022-02-03T16:07:15.300758Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/vincent/Kaggle/data/tensorflow-great-barrier-reef/sliced/S400xS711_MA0.25/annotations/instances_test.json: 100%|█| 2119/2119 [00:00<00:00, 1\n",
      "Annotations /home/vincent/Kaggle/data/tensorflow-great-barrier-reef/sliced/S400xS711_MA0.25/annotations/instances_train.json: 100%|█| 15246/15246 [00:00<00:00\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../JSON2YOLO/\")\n",
    "from general_json2yolo import convert_coco_json\n",
    "annot_coco_dir = project + \"/\" + f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}\" + \"/\" + \"annotations\" + \"/\"\n",
    "convert_coco_json(json_dir = str(annot_coco_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa5fd9",
   "metadata": {},
   "source": [
    "# Create Whole Run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "270a703d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:03:16.043626Z",
     "start_time": "2022-02-03T20:01:44.966357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 5539/5539 [00:00<00:00, 7079.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5539/5539 [01:28<00:00, 62.69it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/annotations_wholeRun_v2.json'\n",
    "name = f\"whole_S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/train/\"\n",
    "json_file = \"instances_train.json\" \n",
    "res = slice_coco(\n",
    "    coco_annotation_file_path = data_path,\n",
    "    image_dir = IMAGE_DIR,\n",
    "    output_dir = project + \"/\" + name,\n",
    "    output_coco_annotation_file_name = json_file,\n",
    "    slice_height = SLICE_HEIGHT,\n",
    "    slice_width = SLICE_WIDTH,\n",
    "    min_area_ratio = min_area_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "253cfd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:04:32.391913Z",
     "start_time": "2022-02-03T20:04:32.371964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vincent/Kaggle/data/tensorflow-great-barrier-reef/sliced//whole_S720xS720_MA0.25/annotations//instances_train.json_coco.json'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "is_train = True\n",
    "post_name = \"train\" if is_train else \"test\"\n",
    "file_pre = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "name =  f\"whole_S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/train/\" if is_train else f\"S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}/images/test\"\n",
    "source_annot = project + \"/\" + name + \"/\" + \"instances_\" + post_name  + \".json_coco.json\"\n",
    "to_annot_folder = project + \"/\" + f\"whole_S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}\" + \"/\" + \"annotations\" + \"/\"\n",
    "to_annot = to_annot_folder + \"/\" \n",
    "if not os.path.exists(to_annot_folder):\n",
    "    os.makedirs(to_annot_folder)\n",
    "shutil.move(source_annot, to_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "604baded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T20:04:36.117239Z",
     "start_time": "2022-02-03T20:04:35.177811Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/vincent/Kaggle/data/tensorflow-great-barrier-reef/sliced/whole_S720xS720_MA0.25/annotations/instances_train.json_coco.json: 100%|█| 14831/14\n"
     ]
    }
   ],
   "source": [
    "annot_coco_dir = project + \"/\" + f\"whole_S{SLICE_HEIGHT}xS{SLICE_WIDTH}_MA{min_area_ratio}\" + \"/\" + \"annotations\" + \"/\"\n",
    "convert_coco_json(json_dir = str(annot_coco_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0b729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
